import streamlit as st
import pandas as pd
import time
import os
import base64
import io
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

# ì•± ì„¤ì •
st.set_page_config(
    page_title="ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬",
    page_icon="ğŸ“°",
    layout="wide"
)

# DataFrameì„ ë‹¤ìš´ë¡œë“œ ë§í¬ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_download_link(df, filename, text):
    towrite = io.BytesIO()
    df.to_excel(towrite, index=False, engine='openpyxl')
    towrite.seek(0)
    b64 = base64.b64encode(towrite.read()).decode()
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}.xlsx">{text}</a>'
    return href

# ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_naver_news(search_keyword, scroll_count, progress_bar, status_text):
    news_data = []
    
    # Chrome ì˜µì…˜ ì„¤ì •
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    
    # ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™”
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    try:
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™
        driver.get(f"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={search_keyword}")
        
        # ìŠ¤í¬ë¡¤ ë° ë°ì´í„° ìˆ˜ì§‘
        for i in range(scroll_count):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
            
            progress_value = (i + 1) / scroll_count
            progress_bar.progress(progress_value)
            status_text.text(f"ìŠ¤í¬ë¡¤ {i+1}/{scroll_count} ì™„ë£Œ")
            
            # ë‰´ìŠ¤ ì•„ì´í…œ ì°¾ê¸°
            news_items = driver.find_elements(By.CSS_SELECTOR, "li.bx")
            
            for item in news_items:
                try:
                    # ë‰´ìŠ¤ ì •ë³´ ì¶”ì¶œ
                    title = item.find_element(By.CSS_SELECTOR, "a.news_tit").text
                    press = item.find_element(By.CSS_SELECTOR, "a.info.press").text
                    
                    # ì‹œê°„ ì •ë³´ì™€ ì§€ë©´ ì •ë³´ ì²˜ë¦¬
                    time_info = ""
                    page_info = ""
                    info_spans = item.find_elements(By.CSS_SELECTOR, "span.info")
                    
                    for span in info_spans:
                        try:
                            if span.find_element(By.CSS_SELECTOR, "i.ico_paper"):
                                page_info = span.text
                        except:
                            if not span.find_elements(By.CSS_SELECTOR, "i"):
                                time_info = span.text
                    
                    # ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬ í™•ì¸
                    naver_news_link = ""
                    try:
                        naver_news_element = item.find_element(By.CSS_SELECTOR, "a.info[href*='news.naver.com']")
                        naver_news_link = naver_news_element.get_attribute("href")
                    except:
                        pass
                    
                    # ë³¸ë¬¸ ì„¤ëª… ì¶”ì¶œ
                    description = item.find_element(By.CSS_SELECTOR, "div.dsc_wrap").text
                    
                    # ë§í¬ ì¶”ì¶œ
                    link = item.find_element(By.CSS_SELECTOR, "a.news_tit").get_attribute("href")
                    
                    # ë‰´ìŠ¤ ì•„ì´í…œ ì €ì¥
                    news_item = {
                        'title': title,
                        'press': press,
                        'time': time_info,
                        'page_info': page_info,
                        'description': description,
                        'link': link,
                        'naver_news_link': naver_news_link
                    }
                    
                    # ì¤‘ë³µ í™•ì¸ í›„ ì¶”ê°€
                    if news_item not in news_data:
                        news_data.append(news_item)
                        
                except Exception as e:
                    continue
        
    except Exception as e:
        status_text.text(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    finally:
        driver.quit()
    
    return news_data

# ë©”ì¸ ì•± í•¨ìˆ˜
def main():
    st.title("ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬")
    st.markdown("ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë¡¤ë§í•˜ì—¬ Excel íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("ê²€ìƒ‰ ì„¤ì •")
        search_keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        scroll_count = st.slider("ìŠ¤í¬ë¡¤ íšŸìˆ˜", min_value=1, max_value=20, value=5, 
                                help="ë” ë§ì€ ê²°ê³¼ë¥¼ ì–»ìœ¼ë ¤ë©´ ìŠ¤í¬ë¡¤ íšŸìˆ˜ë¥¼ ëŠ˜ë¦¬ì„¸ìš”")
        
        start_button = st.button("í¬ë¡¤ë§ ì‹œì‘", disabled=not search_keyword)
    
    # ë©”ì¸ ì˜ì—­
    if not search_keyword:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  í¬ë¡¤ë§ì„ ì‹œì‘í•˜ì„¸ìš”.")
    
    # í¬ë¡¤ë§ ì‹œì‘
    if start_button:
        st.subheader("í¬ë¡¤ë§ ì§„í–‰ ìƒí™©")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        status_text.text("í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        news_data = crawl_naver_news(search_keyword, scroll_count, progress_bar, status_text)
        
        # ê²°ê³¼ í‘œì‹œ
        if not news_data:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(news_data)}ê°œì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            # DataFrame ìƒì„±
            df = pd.DataFrame(news_data)
            
            # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë§í¬
            excel_link = get_download_link(df, f"naver_news_{search_keyword}", "ğŸ“¥ Excel íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
            st.markdown(excel_link, unsafe_allow_html=True)
            
            # ìƒ˜í”Œ ë‰´ìŠ¤ í‘œì‹œ
            st.subheader("ìƒ˜í”Œ ë‰´ìŠ¤")
            for i, news in enumerate(news_data[:3], 1):
                with st.expander(f"ë‰´ìŠ¤ {i}: {news['title']}"):
                    st.write(f"**ì–¸ë¡ ì‚¬:** {news['press']}")
                    st.write(f"**ì‹œê°„:** {news['time']}")
                    if news['page_info']:
                        st.write(f"**ì§€ë©´ ì •ë³´:** {news['page_info']}")
                    st.write(f"**ë‚´ìš©:** {news['description']}")
                    st.write(f"**ë§í¬:** [{news['link']}]({news['link']})")
                    if news['naver_news_link']:
                        st.write(f"**ë„¤ì´ë²„ ë‰´ìŠ¤ ë§í¬:** [{news['naver_news_link']}]({news['naver_news_link']})")
            
            # ì „ì²´ ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
            st.subheader("ì „ì²´ ë°ì´í„°")
            st.dataframe(df)

if __name__ == "__main__":
    main()